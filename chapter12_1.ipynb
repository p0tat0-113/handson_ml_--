{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 텐서플로우 훑어보기\n",
   "id": "c0dc2d158466a370"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 텐서와 연산",
   "id": "d7deaeca7c72703d"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:18.902028Z",
     "start_time": "2025-02-05T17:56:15.871427Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/barrett11357/coding/pycharm/handson_ml_--/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "텐서플로우 API는 텐서를 순환시킨다. 텐서는 넘파이 ndadday와 매우 비슷하다. 즉 텐서는 일반적으로 다차원 배열이다. 하지만 스칼라 값도 가질 수 있다.\n",
    "\n",
    "사용자 정의 함수, 사용자 정의 지표, 사용자 정의 층 등을 만들 때 텐서가 중요하다.\n",
    "\n"
   ],
   "id": "9a17a1a8232a495f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "`tf.constant()`함수로 텐서를 만들 수 있다.",
   "id": "b42bda18de98703f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:18.932053Z",
     "start_time": "2025-02-05T17:56:18.906926Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 실수 값을 가지는 2행 3열의 텐서\n",
    "# ndarray와 마찬가지로 shape와 dtype을 가진다.\n",
    "\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(t)\n",
    "print(t.shape)\n",
    "print(t.dtype)"
   ],
   "id": "fe61ee1c7c0682fc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "(2, 3)\n",
      "<dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-06 02:56:18.909409: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4\n",
      "2025-02-06 02:56:18.909459: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 16.00 GB\n",
      "2025-02-06 02:56:18.909466: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 5.33 GB\n",
      "2025-02-06 02:56:18.909667: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-02-06 02:56:18.909683: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "인덱스 참조도 ndarray와 매우 비슷하게 작동한다.",
   "id": "4264b4279bf85b5f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.020626Z",
     "start_time": "2025-02-05T17:56:18.953454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(t[:, 1:]) # 모든 행애서 1열 이상의 값만 슬라이싱\n",
    "print(t[:, 1:, tf.newaxis]) # 새로운 차원을 추가"
   ],
   "id": "775ab1a6f2b7f09b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 3.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[[2.]\n",
      "  [3.]]\n",
      "\n",
      " [[5.]\n",
      "  [6.]]], shape=(2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "모든 종류의 텐서 연산이 가능하다. 쉽게 말해 행렬연산이 된다 이 얘기다.",
   "id": "4c50c04c19706b1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.050875Z",
     "start_time": "2025-02-05T17:56:19.024372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(t+10)\n",
    "print(tf.square(t))\n",
    "print(t @ tf.transpose(t)) # 전치 후 행렬 곱 수행"
   ],
   "id": "22f29da856ba1ffb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[14. 32.]\n",
      " [32. 77.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "텐서는 스칼라 값도 가질 수 있다.",
   "id": "8a3d7ca7a6112bff"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.061476Z",
     "start_time": "2025-02-05T17:56:19.057218Z"
    }
   },
   "cell_type": "code",
   "source": "tf.constant(42) # 이 경우 크기는 비어있다.",
   "id": "cf7fb5fa6e0f2117",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "필요한 모든 기본 수학 연산과 넘파이에서 볼 수 있는 대부분의 연산을 제공한다. 일부 함수들은 넘파이와 이름이 다르다. (근데 나는 넘파이 함수도 잘 모름ㅋㅋ)\n",
    "\n",
    "텐서플로의 텐서는 넘파이와 한가지 중요한 차이점이 있는데 텐서플로에서는 전치된 데이터의 복사본으로 새로운 텐서가 만들어지지만, 넘파이에서는 t.T는 동일한 데이터의 전치된 뷰일 뿐이다."
   ],
   "id": "73aca7c3718d326"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 텐서와 넘파이",
   "id": "f9414aa5beff95c9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "텐서와 넘파이는 함께 사용하기 편리하다. 넘파이 배열로 텐서를 만들 수 있고, 그 반대도 가능하다. 넘파이 배열에 텐서플로 연산을 적용할 수 있고, 그 반대도 가능하다.",
   "id": "8ff8da3062d00a00"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.080892Z",
     "start_time": "2025-02-05T17:56:19.073075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "a = np.array([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(a)\n",
    "\n",
    "print(tf.constant(a)) # 넘파이 배열로 텐서를 만들 수도 있다.\n",
    "\n",
    "print(np.array(t)) # 반대로 텐서로 넘파이 배열을 만들 수도 있다.\n",
    "\n",
    "print(tf.square(a)) # 서로 상대의 연산을 이용할 수 있음.\n",
    "print(np.square(t))"
   ],
   "id": "31132460ef518ccc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float64)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float64)\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 타입 변환",
   "id": "92d175fc52fa8676"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "텐서플로는 어떠한 타입변환도 자동으로 수행하지 않는다. 서로 다른 타입끼리 연산하려고 하면 예외 터뜨림.\n",
    "\n",
    "변환이 필요할 때는 `tf.cast()`함수를 사용하면 된다."
   ],
   "id": "c8763f3ef191ab3c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 변수",
   "id": "b2ba5ba5516f2be5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "지금까지 살펴본 tf.Tensor는 변경이 불가능한 불변 객체다. 즉 텐서의 내용을 바꿀 수가 없다. 그래서 일반적인 텐서로는 역전파로 변경되어야 하는 신경망의 가중치를 구현할 수 없음.\n",
    "\n",
    "이것이 `tf.Variable`이 필요한 이유다.\n",
    "\n",
    "기본적으로는 텐서와 비슷하게 작동한다. 하지만 `assign()`메서드를 사용해서 변숫값을 바꿀 수 있다. 혹은 `scatter_update(), scatter_nd_update()`메서드를 사용해서 개별 원소를 수정할 수도 있다."
   ],
   "id": "db2506230c9ca40e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.100211Z",
     "start_time": "2025-02-05T17:56:19.095454Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v = tf.Variable([[1,2,3], [4,5,6]])\n",
    "print(v)"
   ],
   "id": "bba98b7a57ae035",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6]], dtype=int32)>\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:19.246583Z",
     "start_time": "2025-02-05T17:56:19.122415Z"
    }
   },
   "cell_type": "code",
   "source": [
    "v.assign(v*2)\n",
    "print(v) # 가변 객체의 성질을 확인할 수 있다.\n",
    "\n",
    "v[0,0].assign(100)\n",
    "print(v)\n",
    "\n",
    "v[:, 2].assign([1,1])\n",
    "print(v)\n",
    "\n",
    "# 직접 수정은 안된다.\n",
    "v[0] = [4,5,6]"
   ],
   "id": "52c471a544da6f63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[ 2,  4,  6],\n",
      "       [ 8, 10, 12]], dtype=int32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[100,   4,   6],\n",
      "       [  8,  10,  12]], dtype=int32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[100,   4,   1],\n",
      "       [  8,  10,   1]], dtype=int32)>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 11\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28mprint\u001B[39m(v)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# 직접 수정은 안된다.\u001B[39;00m\n\u001B[0;32m---> 11\u001B[0m \u001B[43mv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m \u001B[38;5;241m=\u001B[39m [\u001B[38;5;241m4\u001B[39m,\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m6\u001B[39m]\n",
      "\u001B[0;31mTypeError\u001B[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "실전에서 변수를 직접 만들고 수동으로 값을 업데이트 하는 일은 매우 드물 것이라고 함.",
   "id": "3d7db91024be4432"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 사용자 정의 모델과 훈련 알고리즘",
   "id": "4cdb17d3ab8b8070"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 사용자 정의 손실 함수(후버손실 구현)",
   "id": "e9a287321d873779"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**후버** 손실을 직접 구현해보자. 그냥 keras.losses에 있는걸 갖다 써도 되긴 하는데 연습차 직접 구현해보는 것이다.\n",
    "\n",
    "처음에는 단순한 방식으로 구현해보고 문제점을 파악하면서 리팩토링 해볼 것이다. 일단 얘만 좀 복잡하게 설명하면서 하면 나머지들은 거의 비슷함.\n",
    "\n",
    "후버 손실은 MSE와 MAE를 결합한 손실함수다. 구조는 매우 단순한데 임계값을 기준으로 손실이 작으면 MSE, 손실이 크면 MAE를 적용한다. 이게 끝이다.\n",
    "\n",
    "레이블과 모델의 예측을 매개변수로 받는 함수를 만들고, 텐서플로 연산을 사용해서 **각 샘플의 손실을 모두 담은 텐서를 계산하면 된다.**"
   ],
   "id": "d4e903ceebc9eb40"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T17:56:46.965868Z",
     "start_time": "2025-02-05T17:56:46.963200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def hubber_fn(label, y_predict):\n",
    "    error = label - y_predict # 손실 텐서\n",
    "    is_small_error = tf.abs(error) < 1 # 손실이 임계값 1보다 작은지 기록한 이진 벡터\n",
    "    squared_loss = tf.square(error)/2 # MSE 계산\n",
    "    linear_loss = tf.abs(error) - 0.5 # MAE 계산\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss) # tf.where()조건부 선택 함수, True면 앞의 값, False면 뒤의 값을 선택"
   ],
   "id": "9e7929592897eff8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "중요! **성능을 생각한다면 이 코드와 같이 반복문을 사용하지 않고 벡터화해서 구현해야 한다고 한다. 그리고 텐서플로 그래프 최적화의 장점을 사용하려면 텐서플로 연산만 사용해야 한다고 한다.**",
   "id": "bad892e539e7bc5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이제 이 손실함수를 사용해서 모델을 컴파일 할 수 있다. 이게 끝이다!!",
   "id": "6296d62fa7a55726"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:01:47.004004Z",
     "start_time": "2025-02-05T18:01:46.992111Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = tf.keras.Model()\n",
    "model.compile(loss=hubber_fn, optimizer='sgd')"
   ],
   "id": "3effc5bfeb9decce",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 사용자 정의 요소를 가진 모델을 저장하고 로드하기",
   "id": "8af2f65e6cfcdfd7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "모델을 저장하는건 아무 문제 없는데, 문제는 로드할 때다. 사용자 정의 요소의 이름과 객체를 매핑한 딕셔너리를 로드 함수의 매개변수로 넣어줘야 한다. 아니면 데코레이터를 붙여줘도 된다. 챕터10의 서브클래싱 API를 사용할 때 똑같은 일을 겪었음.",
   "id": "ffaee11f7ca18def"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:02:00.476828Z",
     "start_time": "2025-02-05T18:02:00.458713Z"
    }
   },
   "cell_type": "code",
   "source": "model.save('my_model_with_custom_loss.keras') # 그냥 하면 됨.",
   "id": "2fc7984aaa540314",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:02:29.879031Z",
     "start_time": "2025-02-05T18:02:29.854613Z"
    }
   },
   "cell_type": "code",
   "source": "model = tf.keras.models.load_model('my_model_with_custom_loss.keras', custom_objects={'hubber_fn': hubber_fn}) # 이렇게 해줘야 한다.",
   "id": "4663892dafab5a31",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 손실 함수가 매개변수를 받게 하자",
   "id": "15b4831b6fcdee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "losses.Loss클래스를 상속한 클래스를 만들고 call(), get_config()메서드를 구현하면 된다. 이게 진짜 좀 제대로 만드는 느낌쓰",
   "id": "d2041da63e55d254"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:17:36.639692Z",
     "start_time": "2025-02-05T18:17:36.636238Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class HuberLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs) # 기본적인 하이퍼파라미터를 **kwargs로 받은 매개변수 값을 부모 클래스의 생성자에 전달\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # 이 메서드는 앞에서 만든 huber_fn 함수와 똑같다.\n",
    "    def call(self, label, y_predict):\n",
    "        error = label - y_predict # 손실 텐서\n",
    "        is_small_error = tf.abs(error) < self.threshold # 손실이 임계값 1보다 작은지 기록한 이진 벡터\n",
    "        squared_loss = tf.square(error)/2 # MSE 계산\n",
    "        linear_loss = tf.abs(error) - 0.5 # MAE 계산\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss) # tf.where()조건부 선택 함수, True면 앞의 값, False면 뒤의 값을 선택\n",
    "\n",
    "    # 이 메서드는 커스텀 클래스의 직렬화와 관련된 중요한 역할을 한다.\n",
    "    # 하이퍼파라미터 이름과 같이 매핑된 딕셔너리를 반환한다. 설정 정보를 반환해서 나중에 모델을 저장하고 다시 저장할 떄 필요한 정보를 저장하는 역할을 한다.\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config() # 먼저 부모클래스의 get_config()메서드를 호출하고, 그 다음 반환된 딕셔너리에 새로운 하이퍼파라미터를 추가한다.\n",
    "        return {**base_config, 'threshold': self.threshold}"
   ],
   "id": "3cd3f805105ba473",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "이제 모델을 컴파일 할 때 이 모델의 인스턴스를 사용하면 된다. **그리고 이제 모델을 저장할 떄 하이퍼파라미터(여기에서는 임계값)도 함께 저장된다.**",
   "id": "91a0d2dc283a3cb2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:19:48.843716Z",
     "start_time": "2025-02-05T18:19:48.816833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.compile(loss=HuberLoss(threshold=1.7), optimizer='sgd')\n",
    "model.save(\"my_model_with_custom_loss.keras\")\n",
    "model = tf.keras.models.load_model(\"my_model_with_custom_loss.keras\", custom_objects={'HuberLoss': HuberLoss})"
   ],
   "id": "83678d1e92927080",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-05T18:19:50.061926Z",
     "start_time": "2025-02-05T18:19:50.059334Z"
    }
   },
   "cell_type": "code",
   "source": "print(model.loss.threshold) # 모델의 임계값이 저장된 것을 확인할 수 있다.",
   "id": "f767b3636ce83b93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7\n"
     ]
    }
   ],
   "execution_count": 30
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
