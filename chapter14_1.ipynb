{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "CNN은 시각 분야에 국한되지 않고, 음성 인식이나 자연어 처리 같은 다른 작업에도 많이 사용된다.",
   "id": "7dbec8d0b7f06b45"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "CNN의 가장 중요한 구성 요소는 **합성곱 층**이다. 합성곱 층의 뉴런의 이전 층의 특성맵들의 모든 픽셀에 연결되는 것이 아니라, 수용장 안에 있는 픽셀들에만 연결된다.\n",
    "\n",
    "아래층에서는 작은 저수준 특성에 집중하고, 그 다음 층에서는 더 큰 고수준 특성으로 조합해 나가도록 도와준다.\n",
    "\n",
    "한 수용장과 다음 수용장 사이의 수평 또는 수직 방향 스텝 크기를 **스트라이드**라고 한다.\n",
    "\n",
    "한 특성맵의 픽셀들은 모두 같은 가중치 세트를 공유한다. 이를 **필터**, 혹은 **커널**이라고 한다. **하나의 필터는 하나의 특성맵**을 만든다. 필터를 수동으로 정의하는 것이 아니다. 경사하강법을 통해 학습된다.\n",
    "\n",
    "필터는 이전 층에 있는 모든 특성 맵에 걸쳐서 확장된다. **이전 층에 채널 수에 대응되는 3차원 행렬을 가지는 것이다.**\n",
    "\n",
    "한 특성맵에 있는 모든 뉴런이 같은 파라미터를 공유하기 때문에, 모델의 전체 파라미터 수가 급격하게 줄어든다. **일단 CNN이 한 지점에서 패턴을 인식하게 학습되었다면 어떤 위치에 있는 패턴도 인식할 수 있다.**"
   ],
   "id": "722db80d9df85838"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 합성곱 층",
   "id": "95c7379311c8757f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "몇개의 이미지 샘플을 로드하고, CenterCrop과 Rescaling 층으로 전처리 한다.",
   "id": "8f5dde0032409f5e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:54.984418Z",
     "start_time": "2025-02-13T15:55:54.924329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import load_sample_images\n",
    "import tensorflow as tf\n",
    "\n",
    "images = load_sample_images()[\"images\"]\n",
    "images = tf.keras.layers.CenterCrop(height=70, width=120)(images)\n",
    "images = tf.keras.layers.Rescaling(scale=1/255)(images)"
   ],
   "id": "ea378ecdd8d518da",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.084690Z",
     "start_time": "2025-02-13T15:55:55.069700Z"
    }
   },
   "cell_type": "code",
   "source": "images.shape",
   "id": "441524c2d9fc325d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 70, 120, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "출력으로 4D 텐서가 나온다. [샘플수, 가로, 세로, 채널] 구성이다.",
   "id": "6b21138e8dab06a1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "2D 합성곱 층을 통과시킨 다음에 출력 shape를 보자.",
   "id": "b9f00d6121603ca7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.294198Z",
     "start_time": "2025-02-13T15:55:55.156332Z"
    }
   },
   "cell_type": "code",
   "source": [
    "conv_layer = tf.keras.layers.Conv2D(filters=32, strides=1, padding=\"same\", kernel_size=3)\n",
    "fmaps = conv_layer(images)\n",
    "fmaps.shape"
   ],
   "id": "b1407c1a5559904c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 70, 120, 32])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "스트라이드는 1, 패딩은 same을 사용해서 가로 세로 크기는 똑같이 나왔다. 그리고 필터를 32개를 사용했기 때문에 32개의 특성맵이 생성되어서 32채널로 출력되었다.\n",
    "\n",
    "`same` 패딩은 출력 특성맵이 입력과 같은 크기가 되도록 입력 가장자리에 충분한 패딩을 추가해준다.\n",
    "\n",
    "`valid` 패딩은 그냥 패딩을 사용하지 않음. 그래서 출력 특성맵의 크기가 줄어든다.\n"
   ],
   "id": "c27b153bb566ed42"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Conv2D 층의 가중치와 편향을 확인해보자.",
   "id": "5510ff766a0132bd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.370376Z",
     "start_time": "2025-02-13T15:55:55.359072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "kernels, biases = conv_layer.get_weights()\n",
    "print(kernels.shape)\n",
    "print(biases.shape)"
   ],
   "id": "8f26e1527e99baff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 3, 32)\n",
      "(32,)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "가중치는 (3, 3, 3, 32) 이렇게 4D 텐서가 나온다. 하나의 커널은 3*3*3 크기이고, 이런 커널이 32개가 있다.\n",
    "\n",
    "편향은 (32,) 이렇게 1D 텐서가 나온다. 커널마다 하나의 편향을 가지고 있다.\n",
    "\n"
   ],
   "id": "35c62467322e9ea6"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 풀링",
   "id": "8c78b7da90040096"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "다이 층의 목적은 계산량과 메모리사용량, 파라미터 수를 줄이기 위해 입력 이미지의 부표본을 만드는 것이다.\n",
    "\n",
    "합성곱 층과 마찬가지로 풀링 층의 각 뉴런은 이전 층의 작은 사각 영역의 수용장 안에 있는 뉴런의 출력과 연결되어 있다. 이전과 동일하게 크기, 스트라이드, 패딩 유형을 지정해야 한다. 하지만 풀링 뉴런은 가중치가 없다. 즉, 최대나 평균 같은 합산 함수를 사용해 입력값을 더하는 것이 전부이다.\n",
    "\n",
    "아주 널리 사용되는 **최대 풀링층**의 경우 각 수용장에서 가장 큰 입력값이 다음 층으로 전달되고, 다른 값은 버려진다.\n",
    "\n",
    "위에서 말한 장점 외에도 최대 풀링은 작은 변화에도 일정 수준의 **불변성**을 만들어준다. CNN에서 몇 개 층마다 최대 풀링 층을 추가하면 전체적으로 일정 수준의 이동 불변성을 얻을 수 있다고 한다. 또한 회전과 확대, 축소에 대해서도 약간의 불변성을 제공한다고 한다.\n",
    "\n",
    "최대 풀링은 단점도 가지고 있는데, 이 층은 매우 파괴적이다. 예를 들어서 커널사이즈가 2이고, 스트라이드 2라면, 면적인 1/4로 줄어든다. 어떤 애플리케이션에는 불변성이 필요하지 않다. **시맨틱 세그멘테이션**의 경우이다. 이 경우 불변성이 아니라 **등변성**이 목표가 된다."
   ],
   "id": "effc0d9dea4e2fae"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.450482Z",
     "start_time": "2025-02-13T15:55:55.443426Z"
    }
   },
   "cell_type": "code",
   "source": "max_pool = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding=\"same\")",
   "id": "eabbf3b91ced1bfe",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "그냥 이렇게 쓰면 된다. 평균 풀링보다 최대 풀링의 성능이 더 좋아서 대부분 최대 풀링층을 사용한다고 한다.",
   "id": "d12ae8101aebd0f4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 깊이 방향 풀링층",
   "id": "8b9a22171af52d18"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "흔하지는 않지만 최대, 평균 풀링은 공간 방향이 아닌, **깊이 방향**으로도 수행될 수 있다고 한다. 이를 통해 CNN이 다양한 특성에 대한 불변성을 학습할 수 있다고 한다.\n",
    "\n",
    "예를 들어서 동일 패턴이 회전된 여러 가지 필터를 학습했을 때 회전에 상관없이 동일한 출력을 만든다고 한다.\n",
    "\n",
    "공간방향 풀링은 이전 층 특성맵들의 가로세로 크기는 줄이지만 차원은 그대로 유지, 깊이방향 풀링은 이전 층 특성맵들의 가로세로 크기는 그대로 유지하지만 차원을 줄이는 것이다.\n",
    "\n",
    "케라스가 깊이 방향 풀링 층을 제공하지는 않지만 사용자 정의 층으로 어렵지 않게 구현할 수 있다."
   ],
   "id": "850ee7679c26a2c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.548978Z",
     "start_time": "2025-02-13T15:55:55.538939Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DepthPool(tf.keras.layers.Layer):\n",
    "    def __init__(self, pool_size=2, **kwargs):\n",
    "        # 층 초기화: pool_size와 추가 인자들을 받아 초기화합니다.\n",
    "        # pool_size: 깊이(채널) 방향으로 몇 개의 채널을 하나로 합칠지 결정합니다.\n",
    "        super().__init__(**kwargs)  # 부모 클래스(tf.keras.layers.Layer)의 초기화 메서드를 호출합니다.\n",
    "        self.pool_size = pool_size  # 전달받은 pool_size 값을 인스턴스 변수에 저장합니다.\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # call 메서드는 입력 데이터를 받아 층의 연산을 수행합니다.\n",
    "        # inputs: 보통 (batch, height, width, channels) 형태의 텐서입니다.\n",
    "\n",
    "        # 1. 입력 텐서의 동적 shape을 얻습니다.\n",
    "        shape = tf.shape(inputs)\n",
    "        # shape는 텐서의 각 차원의 크기를 나타내는 텐서입니다.\n",
    "\n",
    "        # 2. 깊이 방향 풀링을 위해 채널 수를 그룹으로 나눕니다.\n",
    "        # shape[-1]은 입력 텐서의 채널 수입니다.\n",
    "        # pool_size로 나누어 몇 개의 그룹이 생기는지 계산합니다.\n",
    "        groups = shape[-1] // self.pool_size\n",
    "\n",
    "        # 3. 텐서의 shape을 재구성하여 채널 차원을 두 개의 차원(그룹과 그룹 내 채널)으로 분리합니다.\n",
    "        # 새 shape는 기존의 [batch, height, width]와 새로 추가된 [groups, pool_size]를 합친 형태입니다.\n",
    "        new_shape = tf.concat([shape[:-1], [groups, self.pool_size]], axis=0)\n",
    "        # 예시: 원래 shape가 [batch, height, width, channels]였다면,\n",
    "        # 재구성 후에는 [batch, height, width, groups, pool_size] 형태가 됩니다.\n",
    "\n",
    "        # 4. 재구성된 텐서에서 마지막 차원(pool_size)에 대해 최대값을 계산하여 풀링을 수행합니다.\n",
    "        # tf.reduce_max는 지정된 axis에 대해 최대값을 구합니다.\n",
    "        pooled = tf.reduce_max(tf.reshape(inputs, new_shape), axis=-1)\n",
    "        # 이 연산은 각 그룹 내의 pool_size 개의 채널 중 가장 큰 값을 선택하여 깊이를 축소합니다.\n",
    "\n",
    "        # 5. 깊이 방향으로 풀링된 결과를 반환합니다.\n",
    "        return pooled"
   ],
   "id": "9f88b52f85becd4d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 전역 평균 풀링 층",
   "id": "8469bc3515765a69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "얘는 각 특성 맵의 평균을 계산한다. 특성 맵마다 하나의 숫자를 출력한다. 매우 파괴적인 연산이지만 출력 층 직전에 유용하게 쓰인다고 한다.",
   "id": "5002d933a4ff31e2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.580412Z",
     "start_time": "2025-02-13T15:55:55.570985Z"
    }
   },
   "cell_type": "code",
   "source": "tf.keras.layers.GlobalAveragePooling2D()",
   "id": "787764405e6f0fed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x13efba430>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# CNN 구조",
   "id": "c270959c1e855996"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "전형적인 CNN 구조는 합성곱 층을 몇 개 쌓고, 그 다음에 풀링 층을 쌓고, 그 다음에 또 합성곱 층을 몇 개 쌓고, 그 다음에 다시 풀링 층을 쌓는 식이다.\n",
    "\n",
    "풀링 층 때문에 네트워크를 통과할 수록 이미지는 점점 작아지지만, 합성곱 층 때문에 일반적으로 점점 더 깊어진다. 더 많은 특성앱을 가지게 된다.\n",
    "\n",
    "맨 위층에는 몇 개의 FC층으로 구성된 피드포워드 신경망이 추가되고, 마지막 층에서 소프트맥스 함수 등으로 클래스 확률을 출력하는 식으로 예측을 출력한다."
   ],
   "id": "d1cc052362c2275d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "합성곱 층에서 너무 큰 커널을 사용하는 것은 흔한 실수라고 한다. 큰 커널을 하나 쓰는 것보다 작은 커널을 여러개 쓰는게 계산량도 더 적고 더 좋은 성능을 냄.\n",
    "\n",
    "한가지 예외는 첫번째 합성곱 층인데 여기에서는 일반적으로 큰 크기의 커널과 2 이상의 스트라이드를 써서 너무 많은 정보를 잃지 않고 공간 방향 차원을 줄일 수 있다고 한다."
   ],
   "id": "667ed9724a3a902e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "아래 코드는 FashionMNIST 문제를 해결하기 위한 기본적인 CNN모델 코드다.\n",
    "우선은 이렇게 기본적인 CNN코드를 작성한 다음에, 이걸 skip connection을 사용하는 ResNet 구조로 바꿔보자."
   ],
   "id": "bb36e936e6647a4b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T15:55:55.948071Z",
     "start_time": "2025-02-13T15:55:55.637997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "# 기본적인 합성곱 층 기본 매개변수 설정, 여기에서 거의 filters 속성 값만 바꿔가면서 쓸거다.\n",
    "DefaultConv2D = partial(tf.keras.layers.Conv2D, kernel_size=3, padding=\"same\", activation=\"relu\", kernel_initializer=\"he_normal\")\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    DefaultConv2D(filters=64, kernel_size=7, input_shape=[28, 28, 1]),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    DefaultConv2D(filters=128),\n",
    "    DefaultConv2D(filters=128),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    DefaultConv2D(filters=256),\n",
    "    DefaultConv2D(filters=256),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=2, strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(units=128, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=64, activation=\"relu\", kernel_initializer=\"he_normal\"),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(units=10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])"
   ],
   "id": "132276d42800f641",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "모델을 한 번 훈련시켜보자.",
   "id": "9b2790099a3549e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:00:14.133812Z",
     "start_time": "2025-02-13T16:00:13.755333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fashion MNIST 데이터셋 로드\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n"
   ],
   "id": "12b6441f36f4bba7",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:00:15.072737Z",
     "start_time": "2025-02-13T16:00:15.065390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 훈련 데이터와 검증 데이터를 분리\n",
    "# 훈련 50000, 검증 10000, 테스트 10000\n",
    "X_valid = X_train[50000:]\n",
    "y_valid = y_train[50000:]\n",
    "X_train = X_train[:50000]\n",
    "y_train = y_train[:50000]"
   ],
   "id": "5684b1ad348421a",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:00:16.943623Z",
     "start_time": "2025-02-13T16:00:16.923539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def preprocess(X, buffer_size=10000, batch_size=32):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "    dataset = dataset.map(lambda x:x/255, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.map(lambda x:tf.reshape(x, [28,28,1]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.shuffle(buffer_size=buffer_size)\n",
    "    return dataset.batch(batch_size).prefetch(1)"
   ],
   "id": "e2d0c8c93cd79f73",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:00:22.685710Z",
     "start_time": "2025-02-13T16:00:22.542775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train = preprocess(X_train)\n",
    "X_valid = preprocess(X_valid)"
   ],
   "id": "68c9b2f66f5a7cfe",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-13T16:03:30.370665Z",
     "start_time": "2025-02-13T16:03:30.153593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.fit(X_train, y_train, epochs=1)\n",
    "# 수정 필요"
   ],
   "id": "be21b57b8babc7c0",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`y` argument is not supported when using dataset as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/coding/pycharm/handson_ml_--/.venv/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/coding/pycharm/handson_ml_--/.venv/lib/python3.9/site-packages/keras/engine/data_adapter.py:798\u001B[0m, in \u001B[0;36mDatasetAdapter._validate_args\u001B[0;34m(self, y, sample_weights, steps)\u001B[0m\n\u001B[1;32m    796\u001B[0m \u001B[38;5;66;03m# Arguments that shouldn't be passed.\u001B[39;00m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_none_or_empty(y):\n\u001B[0;32m--> 798\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    799\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`y` argument is not supported when using dataset as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    800\u001B[0m     )\n\u001B[1;32m    801\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_none_or_empty(sample_weights):\n\u001B[1;32m    802\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    803\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`sample_weight` argument is not supported when using \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    804\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdataset as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    805\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: `y` argument is not supported when using dataset as input."
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
